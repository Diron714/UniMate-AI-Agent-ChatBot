"""
Embedding Service
Generates vector embeddings for text chunks using sentence-transformers
"""
import os
import logging
from typing import List, Union, Optional
import numpy as np

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    logging.warning("sentence-transformers not available. Install with: pip install sentence-transformers")

logger = logging.getLogger(__name__)


class EmbeddingService:
    """
    Service for generating text embeddings using sentence-transformers
    Uses all-MiniLM-L6-v2 model (384 dimensions, fast and efficient)
    """
    
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        """
        Initialize embedding service
        
        Args:
            model_name: Name of the sentence-transformers model to use
                        Default: all-MiniLM-L6-v2 (384 dimensions)
        """
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            raise ImportError(
                "sentence-transformers is required. "
                "Install with: pip install sentence-transformers"
            )
        
        self.model_name = model_name
        self.model = None
        self.embedding_dimension = None
        self._load_model()
    
    def _load_model(self):
        """Load the sentence-transformers model"""
        try:
            logger.info(f"Loading embedding model: {self.model_name}")
            self.model = SentenceTransformer(self.model_name)
            
            # Get embedding dimension
            test_embedding = self.model.encode("test", convert_to_numpy=True)
            self.embedding_dimension = len(test_embedding)
            
            logger.info(f"Embedding model loaded. Dimension: {self.embedding_dimension}")
            
        except Exception as e:
            logger.error(f"Error loading embedding model: {e}", exc_info=True)
            raise
    
    def generate_embeddings(self, text: Union[str, List[str]], batch_size: int = 32) -> Union[np.ndarray, List[np.ndarray]]:
        """
        Generate embeddings for text or list of texts
        
        Args:
            text: Single text string or list of text strings
            batch_size: Batch size for processing multiple texts
            
        Returns:
            numpy array (single text) or list of numpy arrays (multiple texts)
        """
        if self.model is None:
            raise RuntimeError("Embedding model not loaded")
        
        if isinstance(text, str):
            # Single text
            try:
                embedding = self.model.encode(
                    text,
                    convert_to_numpy=True,
                    normalize_embeddings=True,  # Normalize for cosine similarity
                    show_progress_bar=False
                )
                return embedding
            except Exception as e:
                logger.error(f"Error generating embedding: {e}", exc_info=True)
                raise
        
        elif isinstance(text, list):
            # Multiple texts
            return self.batch_embed(text, batch_size=batch_size)
        
        else:
            raise TypeError(f"Expected str or List[str], got {type(text)}")
    
    def batch_embed(self, texts: List[str], batch_size: int = 32) -> List[np.ndarray]:
        """
        Generate embeddings for multiple texts efficiently
        
        Args:
            texts: List of text strings
            batch_size: Number of texts to process at once
            
        Returns:
            List of numpy arrays (embeddings)
        """
        if self.model is None:
            raise RuntimeError("Embedding model not loaded")
        
        if not texts:
            return []
        
        try:
            # Encode all texts in batches
            embeddings = self.model.encode(
                texts,
                batch_size=batch_size,
                convert_to_numpy=True,
                normalize_embeddings=True,
                show_progress_bar=len(texts) > 100  # Show progress for large batches
            )
            
            # Convert to list of arrays
            embeddings_list = [embeddings[i] for i in range(len(embeddings))]
            
            logger.info(f"Generated {len(embeddings_list)} embeddings")
            return embeddings_list
            
        except Exception as e:
            logger.error(f"Error in batch embedding: {e}", exc_info=True)
            raise
    
    def get_embedding_dimension(self) -> int:
        """
        Get the dimension of embeddings generated by this model
        
        Returns:
            Embedding dimension (e.g., 384 for all-MiniLM-L6-v2)
        """
        if self.embedding_dimension is None:
            raise RuntimeError("Model not loaded")
        return self.embedding_dimension
    
    def encode_query(self, query: str) -> np.ndarray:
        """
        Encode a search query into an embedding vector
        
        Args:
            query: Search query text
            
        Returns:
            numpy array embedding
        """
        return self.generate_embeddings(query)

